%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Diskussion und Ausblick
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Discussion and Outlook}
  \label{Discussion}
  
\section{Evaluation on new Buildings}
In the preceding sections, we presented the theoretical foundations and development of our social approach to reducing fossil energy consumption. This chapter will evaluate our method on a new set of buildings. For the assessment, we selected the six buildings 1, 2, 4, 6, 9 and 14 (see Section~\ref{sec:building-data}), which we will refer to as evaluation buildings. These buildings were not included in the training set to avoid overlap. Using the same hyperparameters, reward function, and early stopping method, we first used the asocial SAC algorithm to train each building.

\begin{figure}[htb]
\center
     \includegraphics[width=\textwidth]{figures/eval_kpis.pdf}
  \caption{}
  \label{fig:eval-kpis}
\end{figure}

Figure~\ref{fig:eval-kpis} shows the KPI results of the RBC and SAC agents for both the training and evaluation buildings. The performance of the RBC agents is consistent across the building sets, with a slight improvement in the utilization of produced solar energy in the evaluation group. This indicates that when deploying RBC in evaluation buildings, the increase in the use of fossil fuels compared to without using the battery is similar to that of training buildings. 

On the other hand, the SAC agents of the evaluation buildings perform better than the baseline SAC agents in all KPIs except for the share of total renewable energy used. Notably, using battery storage in evaluation buildings facilitates an additional reduction of fossil energy consumption by approximately 1 \% compared to the training group.

\begin{figure}[htb]
\center
     \includegraphics[width=\textwidth]{figures/eval_results.pdf}
  \caption{}
  \label{fig:eval-results}
\end{figure}
  
\section{Final Discussion}
policy loss good indicator for final performance and stability of results

 Experiments mostly only one time --> more robust results if more often and than e.g. mean 
 
 MARLISA performance in paper unclear since compared to RBC, but values of RBC not given and in our case RBC worse than without battery

Social I:
Operates on policy update --> increasing value decreases the loss (not wanted), but increasing the probability more shifts the action to even more randomness. Also not exactly what we aimed. 


forwards perfect forward (but also for baseline)

pretrained Demonstrators trained on the same data of year (same weather, same fuelmix time series)

additional evaluation on new weather and consumption data of same buildings

pearson  correlation only linear
\todo[inline]{demonstrator policy update could be tried to improve more, e.g. second autotuned learning rate, other imitation learning rates, etc.}

\section{Outlook}

\subsection{Value Shaping}
Reward from Demonstrator mit einbeziehen ($-->$ Value Shaping)

In paper value function is updated, very similar to our social agent II. but since we use the absolute things there, its still frequency depending 

\subsection{Cluster Buildings}
Cluster by e.g. energy consumption or size of battery compared to consumption or PV etc etc and then use demonstrator per cluster